{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7014f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "import ast\n",
    "# make deterministic\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from collections import deque\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "import blosc\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "from CasualGPT.utils import set_seed\n",
    "from CasualGPT.GPT_model_returnscore import GPT, GPTConfig\n",
    "from CasualGPT.GPT_trainer_returnscore import Trainer, TrainerConfig\n",
    "from CasualGPT.utils import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab131a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=123)\n",
    "parser.add_argument('--context_length', type=int, default=30)\n",
    "parser.add_argument('--epochs', type=int, default=5)\n",
    "parser.add_argument('--model_type', type=str, default='reward_conditioned')\n",
    "parser.add_argument('--num_steps', type=int, default=500000)\n",
    "parser.add_argument('--num_buffers', type=int, default=50)\n",
    "parser.add_argument('--game', type=str, default='Breakout')\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "# \n",
    "parser.add_argument('--trajectories_per_buffer', type=int, default=10, help='Number of trajectories to sample from each of the buffers.')\n",
    "parser.add_argument('--data_dir_prefix', type=str, default='./dqn_replay/')\n",
    "parser.add_argument('-f')\n",
    "args = parser.parse_args()\n",
    "\n",
    "set_seed(args.seed)\n",
    "\n",
    "class StateActionReturnDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size, actions,actions_neg, actions_len, return_step, done_idxs, rtgs, timesteps):        \n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = 5010\n",
    "        # self.vocab_size = actions.shape[0] \n",
    "        self.data = data\n",
    "        self.actions = actions\n",
    "        self.actions_neg = actions_neg\n",
    "        self.actions_len = actions_len\n",
    "        self.return_step = return_step\n",
    "        self.done_idxs = done_idxs\n",
    "        self.rtgs = rtgs\n",
    "        self.timesteps = timesteps\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        block_size = self.block_size // 3\n",
    "        done_idx = idx + block_size\n",
    "        for i in self.done_idxs:\n",
    "            if i > idx and i>block_size: # first done_idx greater than idx\n",
    "                done_idx = min(int(i), done_idx)\n",
    "                break\n",
    "        idx = done_idx - block_size\n",
    "        # states = torch.tensor(np.array(self.data[idx:done_idx]), dtype=torch.float32).reshape(block_size, -1) # (block_size, 4*84*84)\n",
    "        # states = states / 255.\n",
    "        # states = torch.tensor(self.data[idx:done_idx], dtype=torch.long).unsqueeze(1)\n",
    "        # actions = torch.tensor(self.actions[idx:done_idx], dtype=torch.long).unsqueeze(1) # (block_size, 1)\n",
    "        states = torch.tensor(self.data[idx:done_idx], dtype=torch.long)\n",
    "        actions = torch.tensor(self.actions[idx:done_idx], dtype=torch.long)\n",
    "        actions_neg = torch.tensor(self.actions_neg[idx:done_idx], dtype=torch.long)\n",
    "        actions_len = torch.tensor(self.actions_len[idx:done_idx], dtype=torch.long)\n",
    "        return_step = torch.tensor(self.return_step[idx:done_idx], dtype=torch.float32)\n",
    "        \n",
    "        rtgs = torch.tensor(self.rtgs[idx:done_idx], dtype=torch.float32).unsqueeze(1)\n",
    "        timesteps = torch.tensor(self.timesteps[idx:idx+1], dtype=torch.int64).unsqueeze(1)\n",
    "        return states, actions,actions_neg, actions_len, return_step, rtgs, timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab05e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Rec accuracy\n",
    "\n",
    "# data_load_num\n",
    "# 小于4893\n",
    "idx_num=3000\n",
    "\n",
    "\n",
    "#划分数据集\n",
    "idx_num_train = int(0.8 * idx_num)\n",
    "idx_num_test = idx_num-idx_num_train\n",
    "\n",
    "user_retain = pd.read_csv('./Data/DT_session_4_08_to_5_08_Pure_r2.csv')\n",
    "done_idx_seq = pd.read_csv('./Data/done_idx_seq.csv')\n",
    "\n",
    "rtgs=user_retain['rtg'].values\n",
    "actions_len=user_retain['actions_len'].values\n",
    "return_step=user_retain['return'].values\n",
    "timesteps=user_retain['session'].values\n",
    "done_idxs = done_idx_seq['done_idx'].values\n",
    "obss = user_retain['obss'].values\n",
    "actions = user_retain['actions'].values\n",
    "actions_neg = user_retain['actions'].values\n",
    "\n",
    "obss = np.array([ast.literal_eval(i) for i in obss])\n",
    "obss = np.vstack(obss)\n",
    "\n",
    "actions = np.array([ast.literal_eval(i) for i in actions])\n",
    "actions = np.vstack(actions)\n",
    "\n",
    "actions_neg = np.array([ast.literal_eval(i) for i in actions_neg])\n",
    "actions_neg = np.vstack(actions_neg)\n",
    "\n",
    "rtgs = np.array([ast.literal_eval(i) for i in rtgs])\n",
    "rtgs = np.vstack(rtgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb4087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction number is: 43448\n",
      "item number is: 8000\n"
     ]
    }
   ],
   "source": [
    "vocab_size=8000\n",
    "# actions, obss, vocab_size = re_index(actions, obss)\n",
    "\n",
    "def timestep_paddle(timesteps_train):\n",
    "    time_flag_train=0\n",
    "    timesteps_list_train=list(timesteps_train)\n",
    "    for i in range(len(timesteps_list_train)):\n",
    "        if timesteps_list_train[i]==0:\n",
    "            time_flag_train+=1\n",
    "            if time_flag_train==2:\n",
    "                timesteps_list_train.insert(i,timesteps_list_train[i-1]+1)\n",
    "                break\n",
    "    timesteps_train=np.array(timesteps_list_train)\n",
    "    return timesteps_train\n",
    "\n",
    "#train_dataset\n",
    "sample_num_train=done_idxs[idx_num_train]\n",
    "#sample_num_train=800\n",
    "obss_train=obss[:sample_num_train]\n",
    "rtgs_train=rtgs[:sample_num_train]\n",
    "actions_train=actions[:sample_num_train]\n",
    "actions_neg_train=actions_neg[:sample_num_train]\n",
    "\n",
    "actions_len_train=actions_len[:sample_num_train]\n",
    "return_step_train=return_step[:sample_num_train]\n",
    "timesteps_train=timesteps[:sample_num_train]\n",
    "done_idxs_train=done_idxs[:idx_num_train+1]\n",
    "timesteps_train=timestep_paddle(timesteps_train)\n",
    "\n",
    "train_dataset = StateActionReturnDataset(obss_train, args.context_length*3, actions_train,actions_neg_train, actions_len_train, return_step_train, done_idxs_train, rtgs_train, timesteps_train)\n",
    "\n",
    "#test_dataset\n",
    "sample_num_test=done_idxs[idx_num]\n",
    "#sample_num_test=1000\n",
    "print('interaction number is:',sample_num_test)\n",
    "obss_test=obss[sample_num_train:sample_num_test]\n",
    "rtgs_test=rtgs[sample_num_train:sample_num_test]\n",
    "actions_test=actions[sample_num_train:sample_num_test]\n",
    "actions_neg_test=actions_neg[sample_num_train:sample_num_test]\n",
    "actions_len_test=actions_len[sample_num_train:sample_num_test]\n",
    "return_step_test=return_step[sample_num_train:sample_num_test]\n",
    "timesteps_test=timesteps[sample_num_train:sample_num_test]\n",
    "done_idxs_test=done_idxs[idx_num_train+1:idx_num+1]-sample_num_train\n",
    "timesteps_test=timestep_paddle(timesteps_test)\n",
    "\n",
    "test_dataset = StateActionReturnDataset(obss_test, args.context_length*3, actions_test,actions_neg_test, actions_len_test, return_step_test, done_idxs_test, rtgs_test, timesteps_test)\n",
    "\n",
    "print('item number is:',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c30e1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 270: train loss 0.75376. lr 5.000000e-03: 100%|█| 271/271 [09:05<00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 18\u001b[0m\n\u001b[1;32m     12\u001b[0m tconf \u001b[38;5;241m=\u001b[39m TrainerConfig(max_epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m,\n\u001b[1;32m     13\u001b[0m                       lr_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, warmup_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m, final_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;241m*\u001b[39margs\u001b[38;5;241m.\u001b[39mcontext_length\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     14\u001b[0m                       num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, seed\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mseed, model_type\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel_type, game\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mgame, max_timestep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29\u001b[39m)\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, train_dataset, test_dataset, tconf)\n\u001b[0;32m---> 18\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/DT4MTR/mingpt/trainer_seq.py:227\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     time1\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 227\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     time2\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mprint\u001b[39m(time2\u001b[38;5;241m-\u001b[39mtime1)\n",
      "File \u001b[0;32m~/DT4MTR/mingpt/trainer_seq.py:168\u001b[0m, in \u001b[0;36mTrainer.train.<locals>.run_epoch\u001b[0;34m(split, epoch_num)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_train:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(is_train):\n\u001b[0;32m--> 168\u001b[0m         y_pred,return_batch\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_seq2seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m         return_total\u001b[38;5;241m.\u001b[39mappend(return_batch)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_train:\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# backprop and update the parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/DT4MTR/mingpt/model_seq.py:671\u001b[0m, in \u001b[0;36mGPT.predict_seq2seq\u001b[0;34m(self, states, actions, actions_len, targets, rtgs, r_step, timesteps, num_steps, device, save_attention_weights)\u001b[0m\n\u001b[1;32m    668\u001b[0m         y_pred[i,j,:] \u001b[38;5;241m=\u001b[39m y_seq\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m similar \u001b[38;5;241m=\u001b[39m \u001b[43mbleu_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# Determine the category for r_step[i,j]\u001b[39;00m\n\u001b[1;32m    674\u001b[0m category_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(r_step[i,j]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m)\n",
      "File \u001b[0;32m~/DT4MTR/mingpt/model_seq.py:707\u001b[0m, in \u001b[0;36mbleu_seq\u001b[0;34m(y_pred, y)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_pred[i]\u001b[38;5;241m==\u001b[39my[j]:\n\u001b[1;32m    708\u001b[0m             score_sum\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    709\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mconf = GPTConfig(vocab_size, train_dataset.block_size,\n",
    "                  n_layer=2, n_head=8, n_embd=128, model_type=args.model_type, max_timestep=29)\n",
    "model = GPT(mconf)\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "epochs = args.epochs\n",
    "\n",
    "tconf = TrainerConfig(max_epochs=epochs, batch_size=args.batch_size, learning_rate=0.005,\n",
    "                      lr_decay=False, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*args.context_length*3,\n",
    "                      num_workers=4, seed=args.seed, model_type=args.model_type, game=args.game, max_timestep=29)\n",
    "\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "16.37"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KRL",
   "language": "python",
   "name": "krl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
