{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44b3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import logging\n",
    "# make deterministic\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "import blosc\n",
    "import argparse\n",
    "#from create_dataset import create_dataset\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from CasualGPT.utils import set_seed\n",
    "from CasualGPT.GPT_model_accuracy import GPT, GPTConfig\n",
    "from CasualGPT.GPT_trainer_accuracy import Trainer, TrainerConfig\n",
    "from CasualGPT.utils import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063e685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=123)\n",
    "parser.add_argument('--context_length', type=int, default=30)\n",
    "parser.add_argument('--epochs', type=int, default=5)\n",
    "parser.add_argument('--model_type', type=str, default='reward_conditioned')\n",
    "parser.add_argument('--num_steps', type=int, default=500000)\n",
    "parser.add_argument('--num_buffers', type=int, default=50)\n",
    "parser.add_argument('--game', type=str, default='Breakout')\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "# \n",
    "parser.add_argument('--trajectories_per_buffer', type=int, default=10, help='Number of trajectories to sample from each of the buffers.')\n",
    "parser.add_argument('--data_dir_prefix', type=str, default='./dqn_replay/')\n",
    "parser.add_argument('-f')\n",
    "args = parser.parse_args()\n",
    "\n",
    "set_seed(args.seed)\n",
    "\n",
    "class StateActionReturnDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size, actions, actions_neg, actions_len, return_step, done_idxs, rtgs, timesteps):        \n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = 5010\n",
    "        # self.vocab_size = actions.shape[0] \n",
    "        self.data = data\n",
    "        self.actions = actions\n",
    "        self.actions_neg = actions_neg\n",
    "        self.actions_len = actions_len\n",
    "        self.return_step = return_step\n",
    "        self.done_idxs = done_idxs\n",
    "        self.rtgs = rtgs\n",
    "        self.timesteps = timesteps\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        block_size = self.block_size // 3\n",
    "        done_idx = idx + block_size\n",
    "        for i in self.done_idxs:\n",
    "            if i > idx and i>block_size: # first done_idx greater than idx\n",
    "                done_idx = min(int(i), done_idx)\n",
    "                break\n",
    "        idx = done_idx - block_size\n",
    "        # states = torch.tensor(np.array(self.data[idx:done_idx]), dtype=torch.float32).reshape(block_size, -1) # (block_size, 4*84*84)\n",
    "        # states = states / 255.\n",
    "        # states = torch.tensor(self.data[idx:done_idx], dtype=torch.long).unsqueeze(1)\n",
    "        # actions = torch.tensor(self.actions[idx:done_idx], dtype=torch.long).unsqueeze(1) # (block_size, 1)\n",
    "        states = torch.tensor(self.data[idx:done_idx], dtype=torch.long)\n",
    "        actions = torch.tensor(self.actions[idx:done_idx], dtype=torch.long)\n",
    "        actions_neg = torch.tensor(self.actions_neg[idx:done_idx], dtype=torch.long)\n",
    "        actions_len = torch.tensor(self.actions_len[idx:done_idx], dtype=torch.long)\n",
    "        return_step = torch.tensor(self.return_step[idx:done_idx], dtype=torch.float32)\n",
    "        \n",
    "        rtgs = torch.tensor(self.rtgs[idx:done_idx], dtype=torch.float32).unsqueeze(1)\n",
    "        timesteps = torch.tensor(self.timesteps[idx:idx+1], dtype=torch.int64).unsqueeze(1)\n",
    "        return states, actions, actions_neg, actions_len, return_step, rtgs, timesteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7e77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Rec accuracy\n",
    "\n",
    "# data_load_num\n",
    "idx_num=3000\n",
    "\n",
    "\n",
    "idx_num_train = int(0.8 * idx_num)\n",
    "idx_num_test = idx_num-idx_num_train\n",
    "\n",
    "user_retain = pd.read_csv('./Data/DT_session_4_08_to_5_08_Pure_r2.csv')\n",
    "done_idx_seq = pd.read_csv('./Data/done_idx_seq.csv')\n",
    "\n",
    "rtgs=user_retain['rtg'].values\n",
    "actions_len=user_retain['actions_len'].values\n",
    "return_step=user_retain['return'].values\n",
    "timesteps=user_retain['session'].values\n",
    "done_idxs = done_idx_seq['done_idx'].values\n",
    "obss = user_retain['obss'].values\n",
    "actions = user_retain['actions'].values\n",
    "actions_neg = user_retain['actions'].values\n",
    "\n",
    "obss = np.array([ast.literal_eval(i) for i in obss])\n",
    "obss = np.vstack(obss)\n",
    "\n",
    "actions = np.array([ast.literal_eval(i) for i in actions])\n",
    "actions = np.vstack(actions)\n",
    "\n",
    "actions_neg = np.array([ast.literal_eval(i) for i in actions_neg])\n",
    "actions_neg = np.vstack(actions_neg)\n",
    "\n",
    "rtgs = np.array([ast.literal_eval(i) for i in rtgs])\n",
    "rtgs = np.vstack(rtgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2c18e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction number is: 43448\n",
      "item number is: 8000\n"
     ]
    }
   ],
   "source": [
    "vocab_size=8000\n",
    "# actions, obss, vocab_size = re_index(actions, obss)\n",
    "\n",
    "\n",
    "def timestep_paddle(timesteps_train):\n",
    "    time_flag_train=0\n",
    "    timesteps_list_train=list(timesteps_train)\n",
    "    for i in range(len(timesteps_list_train)):\n",
    "        if timesteps_list_train[i]==0:\n",
    "            time_flag_train+=1\n",
    "            if time_flag_train==2:\n",
    "                timesteps_list_train.insert(i,timesteps_list_train[i-1]+1)\n",
    "                break\n",
    "    timesteps_train=np.array(timesteps_list_train)\n",
    "    return timesteps_train\n",
    "\n",
    "\n",
    "\n",
    "#train_dataset\n",
    "sample_num_train=done_idxs[idx_num_train]\n",
    "obss_train=obss[:sample_num_train]\n",
    "rtgs_train=rtgs[:sample_num_train]\n",
    "actions_train=actions[:sample_num_train]\n",
    "actions_neg_train=actions_neg[:sample_num_train]\n",
    "\n",
    "actions_len_train=actions_len[:sample_num_train]\n",
    "return_step_train=return_step[:sample_num_train]\n",
    "timesteps_train=timesteps[:sample_num_train]\n",
    "done_idxs_train=done_idxs[:idx_num_train+1]\n",
    "timesteps_train=timestep_paddle(timesteps_train)\n",
    "\n",
    "train_dataset = StateActionReturnDataset(obss_train, args.context_length*3, actions_train,actions_neg_train, actions_len_train, return_step_train, done_idxs_train, rtgs_train, timesteps_train)\n",
    "\n",
    "#test_dataset\n",
    "sample_num_test=done_idxs[idx_num]\n",
    "print('interaction number is:',sample_num_test)\n",
    "obss_test=obss[sample_num_train:sample_num_test]\n",
    "rtgs_test=rtgs[sample_num_train:sample_num_test]\n",
    "actions_test=actions[sample_num_train:sample_num_test]\n",
    "actions_neg_test=actions_neg[sample_num_train:sample_num_test]\n",
    "actions_len_test=actions_len[sample_num_train:sample_num_test]\n",
    "return_step_test=return_step[sample_num_train:sample_num_test]\n",
    "timesteps_test=timesteps[sample_num_train:sample_num_test]\n",
    "done_idxs_test=done_idxs[idx_num_train+1:idx_num+1]-sample_num_train\n",
    "timesteps_test=timestep_paddle(timesteps_test)\n",
    "\n",
    "test_dataset = StateActionReturnDataset(obss_test, args.context_length*3, actions_test,actions_neg_test, actions_len_test, return_step_test, done_idxs_test, rtgs_test, timesteps_test)\n",
    "\n",
    "print('item number is:',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0bbc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 270: train loss 0.62232. lr 5.000000e-03: 100%|██████████| 271/271 [16:29<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score is: 0.5628247284905342\n",
      "rouge score is: 0.4480247554301893\n",
      "hr is: 0.3442370927358013\n",
      "NDCG is: 0.3573129070162261\n",
      "CTR Precision is: 0.35834594478955384\n",
      "229.65744256973267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 iter 270: train loss 0.41076. lr 5.000000e-03: 100%|██████████| 271/271 [16:35<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score is: 0.8033122570148747\n",
      "rouge score is: 0.7691805062542257\n",
      "hr is: 0.7049683855223121\n",
      "NDCG is: 0.72163925723982\n",
      "CTR Precision is: 0.7254318268255574\n",
      "135.22724318504333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 iter 270: train loss 0.31909. lr 5.000000e-03: 100%|██████████| 271/271 [16:31<00:00,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score is: 0.8638102708755918\n",
      "rouge score is: 0.8354964952036851\n",
      "hr is: 0.7957154063133871\n",
      "NDCG is: 0.8090037762205243\n",
      "CTR Precision is: 0.8159080644650099\n",
      "112.02766847610474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 iter 270: train loss 0.20097. lr 5.000000e-03: 100%|██████████| 271/271 [16:31<00:00,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score is: 0.8737445328346858\n",
      "rouge score is: 0.8762037667976671\n",
      "hr is: 0.8106167992520285\n",
      "NDCG is: 0.8261399309161538\n",
      "CTR Precision is: 0.8281971031947261\n",
      "107.3529965877533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 iter 12: train loss 0.21690. lr 5.000000e-03:   5%|▍         | 13/271 [00:53<17:32,  4.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m tconf \u001b[38;5;241m=\u001b[39m TrainerConfig(max_epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m,\n\u001b[1;32m     11\u001b[0m                       lr_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, warmup_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m, final_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;241m*\u001b[39margs\u001b[38;5;241m.\u001b[39mcontext_length\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     12\u001b[0m                       num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, seed\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mseed, model_type\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel_type, game\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mgame, max_timestep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29\u001b[39m)\n\u001b[1;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, train_dataset, test_dataset, tconf)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/liushuchang/.jupyter/Ziru_workspace/DT4MTR-main/mingpt/trainer_acc.py:221\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# counter used for learning rate decay\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[0;32m--> 221\u001b[0m     \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m         time1\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/home/liushuchang/.jupyter/Ziru_workspace/DT4MTR-main/mingpt/trainer_acc.py:173\u001b[0m, in \u001b[0;36mTrainer.train.<locals>.run_epoch\u001b[0;34m(split, epoch_num)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_train:\n\u001b[1;32m    172\u001b[0m     model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 173\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), config\u001b[38;5;241m.\u001b[39mgrad_norm_clip)\n\u001b[1;32m    175\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/KRL/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/KRL/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mconf = GPTConfig(vocab_size, train_dataset.block_size,\n",
    "                  n_layer=2, n_head=8, n_embd=128, model_type=args.model_type, max_timestep=29)\n",
    "model = GPT(mconf)\n",
    "\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "epochs = args.epochs\n",
    "\n",
    "\n",
    "tconf = TrainerConfig(max_epochs=epochs, batch_size=args.batch_size, learning_rate=0.005,\n",
    "                      lr_decay=False, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*args.context_length*3,\n",
    "                      num_workers=4, seed=args.seed, model_type=args.model_type, game=args.game, max_timestep=29)\n",
    "\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00347e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KRL",
   "language": "python",
   "name": "krl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
